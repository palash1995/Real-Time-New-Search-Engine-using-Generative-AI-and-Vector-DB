According to research by earthweb.com, there are between 2 to 3 million news articles published daily, both online and offline. Keeping up with this influx of news is challenging. To address this, I've created and released a comprehensive mini-course that demonstrates how to construct a News Search Engine step-by-step using Kafka, Bytewax, Vector Databases, and other robust tools and frameworks. In this project, I have developed the skills to set up Upstash Kafka and a serverless Vector Index instance, prepare and test connections, push messages to the Kafka Topic, and query upsert vectors. I have learned to clean raw news article payloads using the unstructured library and format and validate them with Pydantic. Each News API fetches articles in a separate thread, all sharing the same KafkaProducer instance for efficiency and performance. I have mastered stream processing with Bytewax, defining Kafka as the input source to the DataFlow, formatting consumed messages, chunking them using Langchain’s recursive text splitter, and embedding them using the sentence-transformer’s all-MiniLM-L6-v2 (384) model. I have also set the Vector Index as the output source on the Bytewax flow, handling the batching and upserting of vectors to the vector database. Additionally, I have developed the ability to render fetched articles using Streamlit, allowing users to query the database and receive a list of HTML cards (image, title, date, score) for each entry through a UI endpoint. Finally, I have ensured the robustness of the system by conducting unit testing on the news article fetch functionality and the integrity of the Pydantic models.
